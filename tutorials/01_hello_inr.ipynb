{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial 1: Hello INR - Your First Neural Field\n",
        "\n",
        "**Time:** 15 minutes  \n",
        "**Goal:** Understand what INRs are by fitting one to a simple image\n",
        "\n",
        "---\n",
        "\n",
        "## What is an Implicit Neural Representation?\n",
        "\n",
        "Traditional way to store an image:\n",
        "```python\n",
        "image = np.array([[r,g,b], [r,g,b], ...])  # A grid of pixels\n",
        "```\n",
        "\n",
        "INR way:\n",
        "```python\n",
        "def image(x, y):\n",
        "    return neural_network([x, y])  # A function!\n",
        "```\n",
        "\n",
        "**Key insight:** Instead of storing pixel values, we store a *function* that generates them.\n",
        "\n",
        "Let's see this in action! \ud83d\ude80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from inr_toolkit.models import SIREN\n",
        "from inr_toolkit.training import Trainer\n",
        "from inr_toolkit.utils import get_image_coordinates, load_image, plot_comparison, psnr\n",
        "\n",
        "# Use GPU if available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create a Simple Test Image\n",
        "\n",
        "Let's create a simple gradient image to fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple gradient image\n",
        "height, width = 128, 128\n",
        "x = np.linspace(0, 1, width)\n",
        "y = np.linspace(0, 1, height)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "# Create RGB gradient\n",
        "image = np.stack([\n",
        "    X,           # Red increases left to right\n",
        "    Y,           # Green increases top to bottom  \n",
        "    1 - X * Y,   # Blue decreases\n",
        "], axis=-1)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(image)\n",
        "plt.title('Our Test Image (128x128)')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(f'Image shape: {image.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Prepare Training Data\n",
        "\n",
        "For an INR, our training data is:\n",
        "- **Input:** (x, y) coordinates\n",
        "- **Target:** (r, g, b) color values\n",
        "\n",
        "We're teaching the network: \"When I give you coordinate (x,y), output color (r,g,b)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get coordinates for every pixel\n",
        "coords = get_image_coordinates(height, width)  # Shape: (128*128, 2)\n",
        "colors = torch.from_numpy(image.reshape(-1, 3).astype(np.float32))  # Shape: (128*128, 3)\n",
        "\n",
        "print(f'Coordinates shape: {coords.shape}')\n",
        "print(f'Colors shape: {colors.shape}')\n",
        "print(f'\\nExample:')\n",
        "print(f'  Coordinate: {coords[0]}')\n",
        "print(f'  Color: {colors[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create the Neural Field\n",
        "\n",
        "We'll use SIREN - a network with sine activations that works well for smooth images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create SIREN model\n",
        "model = SIREN(\n",
        "    in_dim=2,        # Input: (x, y)\n",
        "    out_dim=3,       # Output: (r, g, b)\n",
        "    hidden_dim=256,  # Width of hidden layers\n",
        "    num_layers=4,    # Depth of network\n",
        ")\n",
        "\n",
        "print(f'Model has {model.count_parameters():,} parameters')\n",
        "print(f'\\nModel architecture:')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Train the Neural Field\n",
        "\n",
        "Now the magic happens - we optimize the network to memorize the image!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create trainer\n",
        "trainer = Trainer(model, lr=1e-4, device=device)\n",
        "\n",
        "# Train!\n",
        "trainer.fit(coords, colors, epochs=500, log_every=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Visualize Results\n",
        "\n",
        "Let's see how well the network learned to represent our image!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate reconstruction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    coords_tensor = coords.to(device)\n",
        "    reconstruction = model(coords_tensor).cpu().numpy()\n",
        "    reconstruction = reconstruction.reshape(height, width, 3)\n",
        "\n",
        "# Calculate PSNR\n",
        "psnr_value = psnr(\n",
        "    torch.from_numpy(reconstruction),\n",
        "    torch.from_numpy(image)\n",
        ")\n",
        "\n",
        "# Plot comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].imshow(image)\n",
        "axes[0].set_title('Original Image')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(np.clip(reconstruction, 0, 1))\n",
        "axes[1].set_title(f'Reconstruction\\nPSNR: {psnr_value:.2f} dB')\n",
        "axes[1].axis('off')\n",
        "\n",
        "difference = np.abs(image - reconstruction)\n",
        "axes[2].imshow(difference)\n",
        "axes[2].set_title('Absolute Difference\\n(Amplified for visibility)')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'\\nReconstruction quality: {psnr_value:.2f} dB PSNR')\n",
        "print(f'(Higher is better, >30 dB is good)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: The Cool Part - Resolution Independence!\n",
        "\n",
        "Since our \"image\" is now a function, we can query it at ANY resolution! \ud83e\udd2f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Render at 2x resolution (256x256)\n",
        "high_res_coords = get_image_coordinates(256, 256).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    high_res = model(high_res_coords).cpu().numpy()\n",
        "    high_res = high_res.reshape(256, 256, 3)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(np.clip(high_res, 0, 1))\n",
        "plt.title('Same Network, 2x Resolution (256x256)!')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print('We trained on 128x128, but can render at any resolution!')\n",
        "print('The network learned the underlying FUNCTION, not just pixel values.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**What you learned:**\n",
        "1. \u2705 INRs represent data as continuous functions, not discrete grids\n",
        "2. \u2705 Training data is (coordinates \u2192 values) pairs\n",
        "3. \u2705 After training, you can query at ANY resolution\n",
        "4. \u2705 SIREN uses sine activations to fit smooth signals\n",
        "\n",
        "**Key insight:** \n",
        "```\n",
        "Traditional: Store N\u00d7M pixels\n",
        "INR: Store a function (neural network weights)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Try it yourself!\n",
        "\n",
        "Experiment with:\n",
        "- Different `hidden_dim` (try 128, 512)\n",
        "- Different `num_layers` (try 2, 6)\n",
        "- More training epochs\n",
        "- Your own images!\n",
        "\n",
        "**Next:** [Tutorial 2 - Fourier Features](02_fourier_features.ipynb) to learn why this is hard for standard MLPs!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
