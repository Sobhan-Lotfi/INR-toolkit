{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial 3: Comparing Architectures\n",
        "\n",
        "**Time:** 25 minutes  \n",
        "**Goal:** Understand when to use SIREN vs Fourier Features vs ReLU MLP\n",
        "\n",
        "---\n",
        "\n",
        "## The Three Architectures\n",
        "\n",
        "| Architecture | Key Feature | Best For |\n",
        "|--------------|-------------|----------|\n",
        "| **ReLU MLP** | Standard activations | Baseline (usually poor) |\n",
        "| **Fourier Features** | Random Fourier mapping | Most tasks, good default |\n",
        "| **SIREN** | Sine activations | Smooth signals, derivatives |\n",
        "\n",
        "Let's compare them head-to-head!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from inr_toolkit.models import ReLUMLP, FourierFeaturesMLP, SIREN\n",
        "from inr_toolkit.training import Trainer\n",
        "from inr_toolkit.utils import get_image_coordinates, psnr, load_image\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Image: Natural Photo\n",
        "\n",
        "Let's use a natural image with both smooth and detailed regions.\n",
        "We'll create a simple test image for this demo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a test image with mixed frequencies\n",
        "height, width = 128, 128\n",
        "\n",
        "x = np.linspace(-2, 2, width)\n",
        "y = np.linspace(-2, 2, height)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "# Create interesting pattern\n",
        "R = np.sqrt(X**2 + Y**2)\n",
        "image = np.stack([\n",
        "    0.5 + 0.5 * np.sin(5 * R) / (1 + R),           # Ripple in red\n",
        "    0.5 + 0.3 * np.cos(3 * X) * np.cos(3 * Y),    # Grid in green\n",
        "    0.5 + 0.4 * np.exp(-R**2 / 2),                # Gaussian in blue\n",
        "], axis=-1)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(np.clip(image, 0, 1))\n",
        "plt.title('Test Image: Mixed Frequencies')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Prepare data\n",
        "coords = get_image_coordinates(height, width)\n",
        "colors = torch.from_numpy(image.reshape(-1, 3).astype(np.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benchmark Setup\n",
        "\n",
        "We'll train all three architectures with the same capacity and compare:\n",
        "1. **Quality** (PSNR)\n",
        "2. **Training Time**\n",
        "3. **Visual Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration (same for all models)\n",
        "config = {\n",
        "    'hidden_dim': 256,\n",
        "    'num_layers': 4,\n",
        "    'lr': 1e-3,\n",
        "    'epochs': 1000,\n",
        "}\n",
        "\n",
        "# Create models\n",
        "models = {\n",
        "    'ReLU MLP': ReLUMLP(\n",
        "        in_dim=2, out_dim=3,\n",
        "        hidden_dim=config['hidden_dim'],\n",
        "        num_layers=config['num_layers']\n",
        "    ),\n",
        "    'Fourier Features': FourierFeaturesMLP(\n",
        "        in_dim=2, out_dim=3,\n",
        "        hidden_dim=config['hidden_dim'],\n",
        "        num_layers=config['num_layers'],\n",
        "        fourier_scale=10.0\n",
        "    ),\n",
        "    'SIREN': SIREN(\n",
        "        in_dim=2, out_dim=3,\n",
        "        hidden_dim=config['hidden_dim'],\n",
        "        num_layers=config['num_layers']\n",
        "    ),\n",
        "}\n",
        "\n",
        "# Show parameter counts\n",
        "print('Model Parameter Counts:')\n",
        "for name, model in models.items():\n",
        "    print(f'  {name:20s}: {model.count_parameters():,} params')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train All Models\n",
        "\n",
        "This will take a few minutes. Watch the progress bars!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f'\\n{\"=\"*60}')\n",
        "    print(f'Training: {name}')\n",
        "    print(f'{\"=\"*60}')\n",
        "    \n",
        "    # Train\n",
        "    trainer = Trainer(model, lr=config['lr'], device=device)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    trainer.fit(coords, colors, epochs=config['epochs'], log_every=250)\n",
        "    train_time = time.time() - start_time\n",
        "    \n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(coords.to(device)).cpu().numpy()\n",
        "        output = output.reshape(height, width, 3)\n",
        "    \n",
        "    psnr_val = psnr(torch.from_numpy(output), torch.from_numpy(image))\n",
        "    \n",
        "    results[name] = {\n",
        "        'output': output,\n",
        "        'psnr': psnr_val,\n",
        "        'time': train_time,\n",
        "        'params': model.count_parameters()\n",
        "    }\n",
        "    \n",
        "    print(f'\\n\u2705 {name}: PSNR = {psnr_val:.2f} dB, Time = {train_time:.1f}s')\n",
        "\n",
        "print(f'\\n{\"=\"*60}')\n",
        "print('Training complete!')\n",
        "print(f'{\"=\"*60}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visual Comparison\n",
        "\n",
        "Let's see the outputs side by side!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Row 1: Reconstructions\n",
        "axes[0, 0].imshow(np.clip(image, 0, 1))\n",
        "axes[0, 0].set_title('Ground Truth', fontsize=14)\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "for ax, (name, res) in zip(axes[0, 1:], list(results.items())[:2]):\n",
        "    ax.imshow(np.clip(res['output'], 0, 1))\n",
        "    ax.set_title(f\"{name}\\nPSNR: {res['psnr']:.2f} dB\", fontsize=14)\n",
        "    ax.axis('off')\n",
        "\n",
        "# Row 2: Third model and error maps\n",
        "name, res = list(results.items())[2]\n",
        "axes[1, 0].imshow(np.clip(res['output'], 0, 1))\n",
        "axes[1, 0].set_title(f\"{name}\\nPSNR: {res['psnr']:.2f} dB\", fontsize=14)\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "# Error maps\n",
        "for ax, (name, res) in zip(axes[1, 1:], results.items()):\n",
        "    error = np.abs(image - res['output'])\n",
        "    ax.imshow(error)\n",
        "    ax.set_title(f\"{name}\\nError Map\", fontsize=12)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quantitative Results\n",
        "\n",
        "Let's see the numbers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create comparison table\n",
        "comparison = []\n",
        "for name, res in results.items():\n",
        "    comparison.append({\n",
        "        'Model': name,\n",
        "        'PSNR (dB)': f\"{res['psnr']:.2f}\",\n",
        "        'Training Time (s)': f\"{res['time']:.1f}\",\n",
        "        'Parameters': f\"{res['params']:,}\"\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(comparison)\n",
        "print('\\n' + '='*70)\n",
        "print('BENCHMARK RESULTS')\n",
        "print('='*70)\n",
        "print(df.to_string(index=False))\n",
        "print('='*70)\n",
        "\n",
        "# Determine winner\n",
        "best_model = max(results.items(), key=lambda x: x[1]['psnr'])[0]\n",
        "print(f\"\\n\ud83c\udfc6 Winner (by PSNR): {best_model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zoomed-In Comparison\n",
        "\n",
        "Let's zoom into a detailed region to see the differences more clearly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define crop region\n",
        "crop_slice = (slice(40, 88), slice(40, 88))\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "# Ground truth\n",
        "axes[0].imshow(np.clip(image[crop_slice], 0, 1))\n",
        "axes[0].set_title('Ground Truth\\n(Zoomed)', fontsize=14)\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Model outputs\n",
        "for ax, (name, res) in zip(axes[1:], results.items()):\n",
        "    ax.imshow(np.clip(res['output'][crop_slice], 0, 1))\n",
        "    ax.set_title(f\"{name}\\n{res['psnr']:.2f} dB\", fontsize=14)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('Look closely at the fine details!')\n",
        "print('ReLU MLP is blurrier, while SIREN and Fourier Features are sharper.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## When to Use Each Architecture?\n",
        "\n",
        "### \ud83d\udd34 ReLU MLP\n",
        "**Use when:** You want a baseline to compare against  \n",
        "**Avoid when:** You need good quality (almost always!)  \n",
        "**Pro:** Simple  \n",
        "**Con:** Poor quality due to spectral bias  \n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udfe2 Fourier Features (Recommended Default)\n",
        "**Use when:** General purpose INR tasks  \n",
        "**Best for:** Most images, signals, volumes  \n",
        "**Pro:** Great quality, easy to tune (just adjust `fourier_scale`)  \n",
        "**Con:** Slightly more parameters than others  \n",
        "\n",
        "---\n",
        "\n",
        "### \ud83d\udd35 SIREN\n",
        "**Use when:** You need smooth derivatives, very smooth signals  \n",
        "**Best for:** Physics simulations, signed distance functions  \n",
        "**Pro:** Excellent for smooth functions, good derivatives  \n",
        "**Con:** Can be sensitive to initialization, harder to tune  \n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udca1 **Practical Recommendation:**\n",
        "**Start with Fourier Features** (`fourier_scale=10.0`).  \n",
        "If you need better derivatives or very smooth outputs, try SIREN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**What you learned:**\n",
        "1. \u2705 How to benchmark different INR architectures\n",
        "2. \u2705 ReLU MLPs are poor for INRs (spectral bias)\n",
        "3. \u2705 Fourier Features are the best general-purpose choice\n",
        "4. \u2705 SIREN excels at smooth signals and derivatives\n",
        "\n",
        "**Decision tree:**\n",
        "```\n",
        "Do you need INR?\n",
        "\u251c\u2500 Yes \u2192 Use Fourier Features (start here!)\n",
        "\u2502   \u251c\u2500 Need derivatives? \u2192 Try SIREN\n",
        "\u2502   \u2514\u2500 General task? \u2192 Stick with Fourier Features\n",
        "\u2514\u2500 No \u2192 Use standard methods\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Congratulations! \ud83c\udf89\n",
        "\n",
        "You've completed all three tutorials and now understand:\n",
        "- What INRs are and how they work\n",
        "- Why Fourier features are necessary\n",
        "- When to use each architecture\n",
        "\n",
        "**Next steps:**\n",
        "- Try the [examples](../examples/) on real images\n",
        "- Read [architecture deep dives](../docs/architectures.md)\n",
        "- Explore [benchmarks](../benchmarks/) for more comparisons\n",
        "- Build your own INR applications!\n",
        "\n",
        "**Questions?** Open an issue on GitHub!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
